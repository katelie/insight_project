{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; float:center}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; float:center}</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# sns.set_context('notebook')\n",
    "# sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set styles, stopwords, define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "    # using a set will make it faster to run through...\n",
    "\n",
    "punctuation = ['.',',',':','!',';','-','?','\"',\"'\",'(',')','—']   \n",
    "other = ['ive','ve', \"i've\", \"i'v\", 'i’ll', 'i’ve', 'i’v']  # 'deb','hideb','don','didn','twaittry','doesn','thank','heydeb',\n",
    "    \n",
    "stops_punc = set(stopwords.words('english') + punctuation)\n",
    "\n",
    "mystops = stopwords.words('english') + punctuation + other\n",
    "mystops_set = set(stopwords.words('english') + punctuation + other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_sentences(comment):\n",
    "    return nltk.sent_tokenize(remove_newlines(comment.lower()))\n",
    "    \n",
    "    \n",
    "# def separate_sentences(frame, identifier, paragraph, how='merge'):\n",
    "#     sentences = pd.concat([pd.Series(row[identifier], tokenize_sentences((row[paragraph]))) for _, row in frame.iterrows()]).reset_index()\n",
    "#     sentences.columns = ['sentence', identifier]\n",
    "    \n",
    "#     if how == 'merge':\n",
    "#         return sentences.merge(frame, left_on=identifier, right_on=identifier, how='outer', sort=False, suffixes=('_l','_r')) \n",
    "#     elif how == 'nomerge': \n",
    "#         return sentences\n",
    "#     else: \n",
    "#         return sentences.merge(frame, left_on=identifier, right_on=identifier, how='outer', sort=False, suffixes=('_l','_r')) \n",
    "\n",
    "# slightly faster version\n",
    "def separate_sentences(frame, identifier, paragraph, how='merge'):\n",
    "    sentences = pd.DataFrame((tokenize_sentences(row[paragraph]) for _, row in frame.iterrows()), index=frame[identifier]).stack()\n",
    "    sentences = sentences.reset_index() [[0, identifier]] # var1 variable is currently labeled 0\n",
    "    sentences.columns = ['sentence', identifier] # renaming var1\n",
    "    \n",
    "    if how == 'merge':\n",
    "        return sentences.merge(frame, left_on=identifier, right_on=identifier, how='outer', sort=False, suffixes=('_l','_r')) \n",
    "    elif how == 'nomerge': \n",
    "        return sentences\n",
    "    else: \n",
    "        return sentences.merge(frame, left_on=identifier, right_on=identifier, how='outer', sort=False, suffixes=('_l','_r')) \n",
    "\n",
    "\n",
    "def make_lowercase(comment):\n",
    "    return remove_newlines(comment.lower())\n",
    "\n",
    "\n",
    "# def tokenize_aslist(comment):\n",
    "#     comment = remove_newlines(comment)\n",
    "#     if comment == []:\n",
    "#         return None\n",
    "#     else: \n",
    "#         return [word for word in word_tokenize(remove_newlines(comment).lower()) if word not in mystops]\n",
    "\n",
    "    \n",
    "def tokenize(comment):\n",
    "    comment = remove_newlines(comment)\n",
    "    if comment == []:\n",
    "        return None\n",
    "    else: \n",
    "        return ' '.join([word for word in word_tokenize(remove_newlines(comment).lower()) if word not in mystops])\n",
    "\n",
    "def ngram(comment):\n",
    "    comment = remove_newlines(comment)\n",
    "    if comment == []:\n",
    "        return None\n",
    "    else: \n",
    "        return [word for word in ngrams(remove_newlines(comment).lower().split(),gram) if word not in mystops]\n",
    "\n",
    "    \n",
    "# def tokenize_stem_aslist(comment):\n",
    "#     tokens = word_tokenize(remove_newlines(comment).lower())\n",
    "#     if tokens == []:\n",
    "#         return None\n",
    "#     else: \n",
    "#         return[porter.stem(word) for word in tokens if word not in mystops]\n",
    "    \n",
    "def tokenize_stem(comment):\n",
    "    tokens = word_tokenize(remove_newlines(comment).lower())\n",
    "    if tokens == []:\n",
    "        return None\n",
    "    else: \n",
    "        return ' '.join([porter.stem(word) for word in tokens if word not in mystops])\n",
    "\n",
    "\n",
    "def remove_newlines(comment):    \n",
    "    return re.sub(r\"\\n\", \" \", comment)\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_comments_data(frame):\n",
    "    # make sure commentIDs are unique ( = row identity)\n",
    "    frame.loc[:,'commentID'] = frame.index\n",
    "\n",
    "    # remove any frame with no comment text\n",
    "    frame = frame.loc[pd.notnull(frame['usercomment']),:]\n",
    "\n",
    "    # replace NaN usernames with 'anon'\n",
    "    frame.loc[:,'username'].fillna('anon', inplace=True)\n",
    "\n",
    "    # tokenize data\n",
    "    frame.loc[:,'usercomment'] = frame.loc[:,'usercomment'].apply(remove_newlines)\n",
    "    frame.loc[:,'usercomment_lower'] = frame.loc[:,'usercomment'].apply(make_lowercase)\n",
    "\n",
    "    frame.loc[:,'tokens'] = frame.loc[:,'usercomment'].apply(tokenize)\n",
    "    frame.loc[:,'tokens_stemmed'] = frame.loc[:,'usercomment'].apply(tokenize_stem)\n",
    "    \n",
    "    frame.dropna(inplace=True)\n",
    "    frame.drop([],axis=0, inplace=True)\n",
    "\n",
    "    \n",
    "    frame2 = separate_sentences(frame, 'commentID','usercomment',how='merge')\n",
    "    frame2.dropna(inplace=True)\n",
    "    frame2.drop([],axis=0, inplace=True)\n",
    "    \n",
    "\n",
    "    frame2.loc[:,'sentence_tokens'] = frame2.loc[:,'sentence'].apply(tokenize)\n",
    "    frame2.loc[:,'sentence_tokens_stemmed'] = frame2.loc[:,'sentence'].apply(tokenize_stem)\n",
    "    \n",
    "    gram = 2\n",
    "    comments_classified.loc[:,'sentence_bigrams'] = comments_classified.loc[:,'sentence'].apply(ngram)\n",
    "    gram = 3\n",
    "    comments_classified.loc[:,'sentence_trigrams'] = comments_classified.loc[:,'sentence'].apply(ngram)\n",
    "    \n",
    "    frame2.dropna(inplace=True)\n",
    "    frame2.drop([],axis=0, inplace=True)\n",
    "\n",
    "#     frame2['sentence_tokens_aslist'] = frame2.sentence.apply(tokenize_aslist)\n",
    "#     frame2 = frame2.dropna()\n",
    "#     frame2 = frame2.drop([],axis=0)\n",
    "\n",
    "#     frame2['sentence_tokens_stemmed_aslist'] = frame2.sentence.apply(tokenize_stem_aslist)\n",
    "#     frame2 = frame2.dropna()\n",
    "#     frame2 = frame2.drop([],axis=0)\n",
    "\n",
    "    return frame, frame2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import & sanity check"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "comments = pd.read_csv('/Users/kateliea/Documents/Insight/project/webscrapers/comments_smittenkitchen_100.csv', index_col=0)\n",
    "recipes = pd.read_csv('/Users/kateliea/Documents/Insight/project/webscrapers/recipes_smittenkitchen_100.csv', index_col=0)\n",
    "\n",
    "comments_classified = pd.read_csv('comments_classified_SK_filtered2000.csv', index_col=0)\n",
    "\n",
    "comments.columns, len(comments), len(recipes), recipes.numberofcomments.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = pd.read_csv('/Users/kateliea/Documents/Insight/project/webscrapers/comments_smittenkitchen_100.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['child_id', 'children', 'commentID', 'comment_time', 'recipenumber',\n",
       "       'title', 'url', 'usercomment', 'username', 'usersite'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_classified = pd.read_csv('comments_classified_SK_filtered2000.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'sentence', 'commentID', 'child_id', 'children',\n",
       "       'comment_time', 'recipenumber', 'title', 'url', 'usercomment',\n",
       "       'username', 'usersite', 'usercomment_lower', 'tokens',\n",
       "       'tokens_stemmed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_classified.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make new dataframe with sentences separated, tokenize everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kateliea/anaconda/envs/py3/lib/python3.5/site-packages/pandas/core/generic.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/kateliea/anaconda/envs/py3/lib/python3.5/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/kateliea/anaconda/envs/py3/lib/python3.5/site-packages/pandas/core/indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/kateliea/anaconda/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/kateliea/anaconda/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "comments_only, comments_with_sentences = preprocess_comments_data(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_with_sentences.to_csv('comments_with_sentences_100.csv'), comments_only.to_csv('comments_only_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27775, 13), (97316, 16))"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_only.shape, comments_with_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gram = 2\n",
    "comments_classified.loc[:,'sentence_bigrams'] = comments_classified.loc[:,'sentence'].apply(ngram)\n",
    "gram = 3\n",
    "comments_classified.loc[:,'sentence_trigrams'] = comments_classified.loc[:,'sentence'].apply(ngram)\n",
    "\n",
    "comments_classified.loc[:,'sentence_tokens'] = comments_classified.loc[:,'sentence'].apply(tokenize)\n",
    "comments_classified.loc[:,'sentence_tokens_stemmed'] = comments_classified.loc[:,'sentence'].apply(tokenize_stem)\n",
    "\n",
    "comments_classified.dropna(inplace=True)\n",
    "comments_classified.drop([],axis=0, inplace=True)\n",
    "\n",
    "comments_classified.to_csv('comments_classified_SK_filtered2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sentence</th>\n",
       "      <th>commentID</th>\n",
       "      <th>child_id</th>\n",
       "      <th>children</th>\n",
       "      <th>comment_time</th>\n",
       "      <th>recipenumber</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>usercomment</th>\n",
       "      <th>username</th>\n",
       "      <th>usersite</th>\n",
       "      <th>usercomment_lower</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>sentence_bigrams</th>\n",
       "      <th>sentence_trigrams</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>sentence_tokens_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>oh my – a little piece of heaven right there a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2009-11-17 11:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>sweet potato buttermilk pie</td>\n",
       "      <td>https://smittenkitchen.com/2009/11/sweet-potat...</td>\n",
       "      <td>Oh my – a little piece of heaven right there a...</td>\n",
       "      <td>Tabitha (From Single to Married)</td>\n",
       "      <td>http://www.fromsingletomarried.com</td>\n",
       "      <td>oh my – a little piece of heaven right there a...</td>\n",
       "      <td>['oh', '–', 'little', 'piece', 'heaven', 'righ...</td>\n",
       "      <td>['oh', '–', 'littl', 'piec', 'heaven', 'right'...</td>\n",
       "      <td>[(oh, my), (my, –), (–, a), (a, little), (litt...</td>\n",
       "      <td>[(oh, my, –), (my, –, a), (–, a, little), (a, ...</td>\n",
       "      <td>oh – little piece heaven right time holidays</td>\n",
       "      <td>oh – littl piec heaven right time holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>yes, please!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2009-11-17 11:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>sweet potato buttermilk pie</td>\n",
       "      <td>https://smittenkitchen.com/2009/11/sweet-potat...</td>\n",
       "      <td>yes, please!</td>\n",
       "      <td>Cari</td>\n",
       "      <td>none</td>\n",
       "      <td>yes, please!</td>\n",
       "      <td>['yes', 'please']</td>\n",
       "      <td>['ye', 'pleas']</td>\n",
       "      <td>[(yes,, please!)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>yes please</td>\n",
       "      <td>ye pleas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>ive never made sweet potato pie!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2009-11-17 11:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>sweet potato buttermilk pie</td>\n",
       "      <td>https://smittenkitchen.com/2009/11/sweet-potat...</td>\n",
       "      <td>Ive never made sweet potato pie! I’d love to t...</td>\n",
       "      <td>Jessica at How Sweet It Is</td>\n",
       "      <td>http://howsweeteats.com</td>\n",
       "      <td>ive never made sweet potato pie! i’d love to t...</td>\n",
       "      <td>['ive', 'never', 'made', 'sweet', 'potato', 'p...</td>\n",
       "      <td>['ive', 'never', 'made', 'sweet', 'potato', 'p...</td>\n",
       "      <td>[(ive, never), (never, made), (made, sweet), (...</td>\n",
       "      <td>[(ive, never, made), (never, made, sweet), (ma...</td>\n",
       "      <td>never made sweet potato pie</td>\n",
       "      <td>never made sweet potato pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>i’d love to try for the holidays!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2009-11-17 11:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>sweet potato buttermilk pie</td>\n",
       "      <td>https://smittenkitchen.com/2009/11/sweet-potat...</td>\n",
       "      <td>Ive never made sweet potato pie! I’d love to t...</td>\n",
       "      <td>Jessica at How Sweet It Is</td>\n",
       "      <td>http://howsweeteats.com</td>\n",
       "      <td>ive never made sweet potato pie! i’d love to t...</td>\n",
       "      <td>['ive', 'never', 'made', 'sweet', 'potato', 'p...</td>\n",
       "      <td>['ive', 'never', 'made', 'sweet', 'potato', 'p...</td>\n",
       "      <td>[(i’d, love), (love, to), (to, try), (try, for...</td>\n",
       "      <td>[(i’d, love, to), (love, to, try), (to, try, f...</td>\n",
       "      <td>i’d love try holidays</td>\n",
       "      <td>i’d love tri holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>this is definitely going on my must make list.</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2009-11-17 11:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>sweet potato buttermilk pie</td>\n",
       "      <td>https://smittenkitchen.com/2009/11/sweet-potat...</td>\n",
       "      <td>This is definitely going on my Must Make list....</td>\n",
       "      <td>LauraC</td>\n",
       "      <td>http://JonAndLaura.blogspot.com</td>\n",
       "      <td>this is definitely going on my must make list....</td>\n",
       "      <td>['definitely', 'going', 'must', 'make', 'list'...</td>\n",
       "      <td>['definit', 'go', 'must', 'make', 'list', 'nor...</td>\n",
       "      <td>[(this, is), (is, definitely), (definitely, go...</td>\n",
       "      <td>[(this, is, definitely), (is, definitely, goin...</td>\n",
       "      <td>definitely going must make list</td>\n",
       "      <td>definit go must make list</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                           sentence  commentID  \\\n",
       "0    other  oh my – a little piece of heaven right there a...          0   \n",
       "1    other                                       yes, please!          1   \n",
       "2    other                   ive never made sweet potato pie!          2   \n",
       "3    other                  i’d love to try for the holidays!          2   \n",
       "4    other     this is definitely going on my must make list.          3   \n",
       "\n",
       "   child_id children         comment_time  recipenumber  \\\n",
       "0         0       no  2009-11-17 11:44:00             0   \n",
       "1         0       no  2009-11-17 11:44:00             0   \n",
       "2         0       no  2009-11-17 11:44:00             0   \n",
       "3         0       no  2009-11-17 11:44:00             0   \n",
       "4         0       no  2009-11-17 11:44:00             0   \n",
       "\n",
       "                         title  \\\n",
       "0  sweet potato buttermilk pie   \n",
       "1  sweet potato buttermilk pie   \n",
       "2  sweet potato buttermilk pie   \n",
       "3  sweet potato buttermilk pie   \n",
       "4  sweet potato buttermilk pie   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://smittenkitchen.com/2009/11/sweet-potat...   \n",
       "1  https://smittenkitchen.com/2009/11/sweet-potat...   \n",
       "2  https://smittenkitchen.com/2009/11/sweet-potat...   \n",
       "3  https://smittenkitchen.com/2009/11/sweet-potat...   \n",
       "4  https://smittenkitchen.com/2009/11/sweet-potat...   \n",
       "\n",
       "                                         usercomment  \\\n",
       "0  Oh my – a little piece of heaven right there a...   \n",
       "1                                       yes, please!   \n",
       "2  Ive never made sweet potato pie! I’d love to t...   \n",
       "3  Ive never made sweet potato pie! I’d love to t...   \n",
       "4  This is definitely going on my Must Make list....   \n",
       "\n",
       "                           username                            usersite  \\\n",
       "0  Tabitha (From Single to Married)  http://www.fromsingletomarried.com   \n",
       "1                              Cari                                none   \n",
       "2        Jessica at How Sweet It Is             http://howsweeteats.com   \n",
       "3        Jessica at How Sweet It Is             http://howsweeteats.com   \n",
       "4                            LauraC     http://JonAndLaura.blogspot.com   \n",
       "\n",
       "                                   usercomment_lower  \\\n",
       "0  oh my – a little piece of heaven right there a...   \n",
       "1                                       yes, please!   \n",
       "2  ive never made sweet potato pie! i’d love to t...   \n",
       "3  ive never made sweet potato pie! i’d love to t...   \n",
       "4  this is definitely going on my must make list....   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['oh', '–', 'little', 'piece', 'heaven', 'righ...   \n",
       "1                                  ['yes', 'please']   \n",
       "2  ['ive', 'never', 'made', 'sweet', 'potato', 'p...   \n",
       "3  ['ive', 'never', 'made', 'sweet', 'potato', 'p...   \n",
       "4  ['definitely', 'going', 'must', 'make', 'list'...   \n",
       "\n",
       "                                      tokens_stemmed  \\\n",
       "0  ['oh', '–', 'littl', 'piec', 'heaven', 'right'...   \n",
       "1                                    ['ye', 'pleas']   \n",
       "2  ['ive', 'never', 'made', 'sweet', 'potato', 'p...   \n",
       "3  ['ive', 'never', 'made', 'sweet', 'potato', 'p...   \n",
       "4  ['definit', 'go', 'must', 'make', 'list', 'nor...   \n",
       "\n",
       "                                    sentence_bigrams  \\\n",
       "0  [(oh, my), (my, –), (–, a), (a, little), (litt...   \n",
       "1                                  [(yes,, please!)]   \n",
       "2  [(ive, never), (never, made), (made, sweet), (...   \n",
       "3  [(i’d, love), (love, to), (to, try), (try, for...   \n",
       "4  [(this, is), (is, definitely), (definitely, go...   \n",
       "\n",
       "                                   sentence_trigrams  \\\n",
       "0  [(oh, my, –), (my, –, a), (–, a, little), (a, ...   \n",
       "1                                                 []   \n",
       "2  [(ive, never, made), (never, made, sweet), (ma...   \n",
       "3  [(i’d, love, to), (love, to, try), (to, try, f...   \n",
       "4  [(this, is, definitely), (is, definitely, goin...   \n",
       "\n",
       "                                sentence_tokens  \\\n",
       "0  oh – little piece heaven right time holidays   \n",
       "1                                    yes please   \n",
       "2                   never made sweet potato pie   \n",
       "3                         i’d love try holidays   \n",
       "4               definitely going must make list   \n",
       "\n",
       "                     sentence_tokens_stemmed  \n",
       "0  oh – littl piec heaven right time holiday  \n",
       "1                                   ye pleas  \n",
       "2                never made sweet potato pie  \n",
       "3                       i’d love tri holiday  \n",
       "4                  definit go must make list  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_classified.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
