{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; float:center}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; float:center}</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import decomposition\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('ticks')\n",
    "\n",
    "punctuation = ['.',',',':','!',';','-','?','\"',\"'\",'(',')','—']   \n",
    "other = ['ive','ve', \"i've\", \"i'v\", 'i’ll', 'i’ve', 'i’v']  # 'deb','hideb','don','didn','twaittry','doesn','thank','heydeb',\n",
    "mystops = stopwords.words('english') + punctuation + other\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import & sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_with_sentences_100_classified = pd.read_csv('comments_with_sentences_100_classified_4classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments_classified = pd.read_csv('comments_classified_SK_filtered2000_additional.csv',index_col=0)\n",
    "\n",
    "comments_with_sentences_100 = pd.read_csv('comments_with_sentences_100.csv',index_col=0)\n",
    "comments_only_100 = pd.read_csv('comments_only_100.csv',index_col=0)\n",
    "\n",
    "comments_with_sentences_all = pd.read_csv('comments_with_sentences_all.csv',index_col=0)\n",
    "comments_only_all = pd.read_csv('comments_only_all.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments_with_sentences = comments_with_sentences.dropna()\n",
    "\n",
    "comments_only_100 = comments_only.dropna()\n",
    "comments_with_sentences_100 = comments_only.dropna()\n",
    "\n",
    "comments_only_all = comments_only_all.dropna()\n",
    "comments_with_sentences_all = comments_only_all.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(comments_only_all.title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments_with_sentences_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process test & train data\n",
    "\n",
    "### define data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_with_sentences_100_classified = comments_with_sentences_100_classified.dropna()\n",
    "# X_train = X_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comments_classified' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f140f748585e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomments_classified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# comments_classified.category.replace('try','other',inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# comments_classified.category.replace('addition','suggestion',inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# comments_classified.category.replace('subtraction','substitution',inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# comments_classified.category.replace('related','other',inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'comments_classified' is not defined"
     ]
    }
   ],
   "source": [
    "comments_classified.category.unique()\n",
    "# comments_classified.category.replace('try','other',inplace=True)\n",
    "# comments_classified.category.replace('addition','suggestion',inplace=True)\n",
    "# comments_classified.category.replace('subtraction','substitution',inplace=True)\n",
    "# comments_classified.category.replace('related','other',inplace=True)\n",
    "# comments_classified.category.replace('question','other',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94611, 20)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_with_sentences_100_classified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode classes labels as ints\n",
    "# though this probably doesn't matter for this? \n",
    "le = LabelEncoder()\n",
    "comments_classified.loc[:,'category_label'] = le.fit_transform(comments_classified.category)\n",
    "\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target.replace(['addition','substitution','omission'],'helpful',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = comments_with_sentences_100_classified.sentence_tokens_stemmed[:50000] #\\.as_matrix()\n",
    "target = comments_with_sentences_100_classified.category[:50000] #.as_matrix()\n",
    "\n",
    "X_test = comments_with_sentences_100_classified.loc[5000:, 'sentence_tokens_stemmed']\n",
    "# X_test2 = comments_with_sentences_all.loc[:10000, 'sentence_tokens_stemmed']\n",
    "# X_test = comments_with_sentences.loc[:, 'tokens_stemmed']\n",
    "\n",
    "# X_train = comments_classified[comments_classified.category != 'other'].sentence #\\.as_matrix()\n",
    "# target = comments_classified[comments_classified.category != 'other'].category_label #.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word relevancy - counter, tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 9665)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3), stop_words=mystops, max_df=50, min_df=5)\n",
    "\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_train_counts.shape\n",
    "\n",
    "transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "\n",
    "X_train_tf = transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just to try to get some sense of the frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61439.640132201399"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf.toarray()[:,vectorizer.vocabulary_.get('suggest')].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = MultinomialNB().fit(X_train_tf, target)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "classifier = BernoulliNB().fit(X_train_counts, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_counts = vectorizer.transform(X_test)\n",
    "X_test_tf = transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n",
      "1015\n"
     ]
    }
   ],
   "source": [
    "predicted = classifier.predict(X_test_tf)\n",
    "\n",
    "# for doc, category in zip(X_test, predicted):\n",
    "# #     if category == 'addition':\n",
    "#     if category != 'other':\n",
    "#         print('%r => %s' % (doc, category))\n",
    "        \n",
    "print(len(predicted[predicted != 'other']))\n",
    "print(len(predicted[predicted == 'helpful']))\n",
    "\n",
    "# for doc, category in zip(X_test[:100], predicted[:100]):\n",
    "#     print('%r => %s' % (doc, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'next time might zest shallot mix' => helpful\n",
      "'seen ottolenghi method remov seed pomegran' => helpful\n",
      "'recip chang' => helpful\n",
      "'mint omit everyth els ad' => helpful\n",
      "'use black cocoa powder recip' => helpful\n",
      "'would suggest mayb fresh garlic instead' => helpful\n",
      "'vegan baker friend make cake take stress day' => helpful\n",
      "'substitu regular cocoa powder' => helpful\n",
      "'chanc nip food shop local tesco pick larg tub green & black’ cocoa powder' => helpful\n",
      "'hope enjoy trip sorri didn’t get one talk mayb next time' => helpful\n",
      "'good tri per recip next time' => helpful\n",
      "'use valrhona cocoa powder cake ghiradelli bake chocol chocol butter cream' => helpful\n",
      "'cake flour work instead all-purpos' => helpful\n",
      "'use dutch process cocoa go forward' => helpful\n",
      "'thought decor somehow mayb instead vanilla buttercream think could fit fill etc' => helpful\n",
      "'would like chocol buttercream frost instead vanilla' => helpful\n",
      "'fyi saw strongli advis reduc sugar went ahead anyway 300g brown sugar instead 380g white sugar' => helpful\n",
      "'husband thought much onion next time make decreas third half everyth els stay' => helpful\n"
     ]
    }
   ],
   "source": [
    "for doc, category in zip(X_test[:3000], predicted[:3000]):\n",
    "#     if category == 'addition':\n",
    "    if category != 'other':\n",
    "        print('%r => %s' % (doc, category))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = MultinomialNB().fit(X_test_tf, predicted)\n",
    "# predicted = classifier.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decomposition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e365c7546d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decomposition' is not defined"
     ]
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components=20)\n",
    "\n",
    "pca.fit(X_train_tf.toarray())\n",
    "X_trans = pca.transform(X_train_tf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_target(df, target_column):\n",
    "    \"\"\"Add column to df with integers for the target.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    df -- pandas DataFrame.\n",
    "    target_column -- column to map to int, producing\n",
    "                     new Target column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_mod -- modified DataFrame.\n",
    "    targets -- list of target names.\n",
    "    \"\"\"\n",
    "    df_mod = df.copy()\n",
    "    targets = df_mod[target_column].unique()\n",
    "    map_to_int = {name: n for n, name in enumerate(targets)}\n",
    "    df_mod[\"Target\"] = df_mod[target_column].replace(map_to_int)\n",
    "\n",
    "    return (df_mod, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = encode_target(comments_classified, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments_classified.loc[comments_classified.sentence.str.contains('instead of') == True, 'category'] = 'substitution'\n",
    "\n",
    "# comments_classified"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "comments_classified[comments_classified.sentence.str.contains('perfect for') == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_classifier = DecisionTreeClassifier(max_depth=3, max_features=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_fit = tree_classifier.fit(X_train_counts, target)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
