{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; float:center}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; float:center}</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "import datetime\n",
    "from itertools import groupby\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "# import scipy as sp\n",
    "# import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wordcloud as wc\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "# from nltk import Text\n",
    "\n",
    "import time\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set styles, stopwords, define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "    # using a set will make it faster to run through...\n",
    "\n",
    "punctuation = ['.',',',':','!',';','-','?','\"',\"'\",'(',')','—']   \n",
    "other = ['ive','ve', \"i've\", \"i'v\", 'i’ll', 'i’ve', 'i’v']  # 'deb','hideb','don','didn','twaittry','doesn','thank','heydeb',\n",
    "    \n",
    "stops_punc = set(stopwords.words('english') + punctuation)\n",
    "\n",
    "mystops = stopwords.words('english') + punctuation + other\n",
    "mystops_set = set(stopwords.words('english') + punctuation + other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_sentences(comment):\n",
    "    return nltk.sent_tokenize(remove_newlines(comment.lower()))\n",
    "    \n",
    "    \n",
    "# def separate_sentences(frame, identifier, paragraph, how='merge'):\n",
    "#     sentences = pd.concat([pd.Series(row[identifier], tokenize_sentences((row[paragraph]))) for _, row in frame.iterrows()]).reset_index()\n",
    "#     sentences.columns = ['sentence', identifier]\n",
    "    \n",
    "#     if how == 'merge':\n",
    "#         return sentences.merge(frame, left_on=identifier, right_on=identifier, how='outer', sort=False, suffixes=('_l','_r')) \n",
    "#     elif how == 'nomerge': \n",
    "#         return sentences\n",
    "#     else: \n",
    "#         return sentences.merge(frame, left_on=identifier, right_on=identifier, how='outer', sort=False, suffixes=('_l','_r')) \n",
    "\n",
    "# slightly faster version\n",
    "def separate_sentences(frame, identifier, paragraph, how='merge'):\n",
    "    sentences = pd.DataFrame((tokenize_sentences(row[paragraph]) for _, row in frame.iterrows()), index=frame[identifier]).stack()\n",
    "    sentences = sentences.reset_index() [[0, identifier]] # var1 variable is currently labeled 0\n",
    "    sentences.columns = ['sentence', identifier] # renaming var1\n",
    "    \n",
    "    if how == 'merge':\n",
    "        return sentences.merge(frame, left_on=identifier, right_on=identifier, how='outer', sort=False, suffixes=('_l','_r')) \n",
    "    elif how == 'nomerge': \n",
    "        return sentences\n",
    "    else: \n",
    "        return sentences.merge(frame, left_on=identifier, right_on=identifier, how='outer', sort=False, suffixes=('_l','_r')) \n",
    "\n",
    "\n",
    "def make_lowercase(comment):\n",
    "    return remove_newlines(comment.lower())\n",
    "\n",
    "\n",
    "# def tokenize_aslist(comment):\n",
    "#     comment = remove_newlines(comment)\n",
    "#     if comment == []:\n",
    "#         return None\n",
    "#     else: \n",
    "#         return [word for word in word_tokenize(remove_newlines(comment).lower()) if word not in mystops]\n",
    "\n",
    "    \n",
    "def tokenize(comment):\n",
    "    comment = remove_newlines(comment)\n",
    "    if comment == []:\n",
    "        return None\n",
    "    else: \n",
    "        return ' '.join([word for word in word_tokenize(remove_newlines(comment).lower()) if word not in mystops])\n",
    "\n",
    "def ngram(comment):\n",
    "    comment = remove_newlines(comment)\n",
    "    if comment == []:\n",
    "        return None\n",
    "    else: \n",
    "        return [word for word in ngrams(remove_newlines(comment).lower().split(),gram) if word not in mystops]\n",
    "\n",
    "    \n",
    "# def tokenize_stem_aslist(comment):\n",
    "#     tokens = word_tokenize(remove_newlines(comment).lower())\n",
    "#     if tokens == []:\n",
    "#         return None\n",
    "#     else: \n",
    "#         return[porter.stem(word) for word in tokens if word not in mystops]\n",
    "    \n",
    "def tokenize_stem(comment):\n",
    "    tokens = word_tokenize(remove_newlines(comment).lower())\n",
    "    if tokens == []:\n",
    "        return None\n",
    "    else: \n",
    "        return ' '.join([porter.stem(word) for word in tokens if word not in mystops])\n",
    "\n",
    "\n",
    "def remove_newlines(comment):    \n",
    "    return re.sub(r\"\\n\", \" \", comment)\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_comments_data(frame):\n",
    "    # make sure commentIDs are unique ( = row identity)\n",
    "    frame.loc[:,'commentID'] = frame.index\n",
    "\n",
    "    # remove any frame with no comment text\n",
    "    frame = frame.loc[pd.notnull(frame['usercomment']),:]\n",
    "\n",
    "    # replace NaN usernames with 'anon'\n",
    "    frame.loc[:,'username'].fillna('anon', inplace=True)\n",
    "\n",
    "    # tokenize data\n",
    "    frame.loc[:,'usercomment'] = frame.loc[:,'usercomment'].apply(remove_newlines)\n",
    "    frame.loc[:,'usercomment_lower'] = frame.loc[:,'usercomment'].apply(make_lowercase)\n",
    "\n",
    "    frame.loc[:,'tokens'] = frame.loc[:,'usercomment'].apply(tokenize)\n",
    "    frame.loc[:,'tokens_stemmed'] = frame.loc[:,'usercomment'].apply(tokenize_stem)\n",
    "    \n",
    "    frame.dropna(inplace=True)\n",
    "    frame.drop([],axis=0, inplace=True)\n",
    "\n",
    "    \n",
    "    frame2 = separate_sentences(frame, 'commentID','usercomment',how='merge')\n",
    "    frame2.dropna(inplace=True)\n",
    "    frame2.drop([],axis=0, inplace=True)\n",
    "    \n",
    "\n",
    "    frame2.loc[:,'sentence_tokens'] = frame2.loc[:,'sentence'].apply(tokenize)\n",
    "    frame2.loc[:,'sentence_tokens_stemmed'] = frame2.loc[:,'sentence'].apply(tokenize_stem)\n",
    "    \n",
    "    gram = 2\n",
    "    comments_classified.loc[:,'sentence_bigrams'] = comments_classified.loc[:,'sentence'].apply(ngram)\n",
    "    gram = 3\n",
    "    comments_classified.loc[:,'sentence_trigrams'] = comments_classified.loc[:,'sentence'].apply(ngram)\n",
    "    \n",
    "    frame2.dropna(inplace=True)\n",
    "    frame2.drop([],axis=0, inplace=True)\n",
    "\n",
    "#     frame2['sentence_tokens_aslist'] = frame2.sentence.apply(tokenize_aslist)\n",
    "#     frame2 = frame2.dropna()\n",
    "#     frame2 = frame2.drop([],axis=0)\n",
    "\n",
    "#     frame2['sentence_tokens_stemmed_aslist'] = frame2.sentence.apply(tokenize_stem_aslist)\n",
    "#     frame2 = frame2.dropna()\n",
    "#     frame2 = frame2.drop([],axis=0)\n",
    "\n",
    "    return frame, frame2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import & sanity check"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "comments = pd.read_csv('/Users/kateliea/Documents/Insight/project/webscrapers/comments_smittenkitchen_100.csv', index_col=0)\n",
    "recipes = pd.read_csv('/Users/kateliea/Documents/Insight/project/webscrapers/recipes_smittenkitchen_100.csv', index_col=0)\n",
    "\n",
    "comments_classified = pd.read_csv('comments_classified_SK_filtered2000.csv', index_col=0)\n",
    "\n",
    "comments.columns, len(comments), len(recipes), recipes.numberofcomments.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = pd.read_csv('/Users/kateliea/Documents/Insight/project/webscrapers/comments_smittenkitchen_100.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['child_id', 'children', 'commentID', 'comment_time', 'recipenumber',\n",
       "       'title', 'url', 'usercomment', 'username', 'usersite'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_classified = pd.read_csv('comments_classified_SK_filtered2000.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'sentence', 'commentID', 'child_id', 'children',\n",
       "       'comment_time', 'recipenumber', 'title', 'url', 'usercomment',\n",
       "       'username', 'usersite', 'usercomment_lower', 'tokens',\n",
       "       'tokens_stemmed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_classified.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make new dataframe with sentences separated, tokenize everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kateliea/anaconda/envs/py3/lib/python3.5/site-packages/pandas/core/generic.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/kateliea/anaconda/envs/py3/lib/python3.5/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/kateliea/anaconda/envs/py3/lib/python3.5/site-packages/pandas/core/indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/kateliea/anaconda/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/kateliea/anaconda/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "comments_only, comments_with_sentences = preprocess_comments_data(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_with_sentences.to_csv('comments_with_sentences_100.csv'), comments_only.to_csv('comments_only_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27775, 13), (97316, 16))"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_only.shape, comments_with_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gram = 2\n",
    "comments_classified.loc[:,'sentence_bigrams'] = comments_classified.loc[:,'sentence'].apply(ngram)\n",
    "gram = 3\n",
    "comments_classified.loc[:,'sentence_trigrams'] = comments_classified.loc[:,'sentence'].apply(ngram)\n",
    "\n",
    "comments_classified.loc[:,'sentence_tokens'] = comments_classified.loc[:,'sentence'].apply(tokenize)\n",
    "comments_classified.loc[:,'sentence_tokens_stemmed'] = comments_classified.loc[:,'sentence'].apply(tokenize_stem)\n",
    "\n",
    "comments_classified.dropna(inplace=True)\n",
    "comments_classified.drop([],axis=0, inplace=True)\n",
    "\n",
    "comments_classified.to_csv('comments_classified_SK_filtered2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sentence</th>\n",
       "      <th>commentID</th>\n",
       "      <th>child_id</th>\n",
       "      <th>children</th>\n",
       "      <th>comment_time</th>\n",
       "      <th>recipenumber</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>usercomment</th>\n",
       "      <th>username</th>\n",
       "      <th>usersite</th>\n",
       "      <th>usercomment_lower</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>sentence_bigrams</th>\n",
       "      <th>sentence_trigrams</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>sentence_tokens_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>oh my – a little piece of heaven right there a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2009-11-17 11:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>sweet potato buttermilk pie</td>\n",
       "      <td>https://smittenkitchen.com/2009/11/sweet-potat...</td>\n",
       "      <td>Oh my – a little piece of heaven right there a...</td>\n",
       "      <td>Tabitha (From Single to Married)</td>\n",
       "      <td>http://www.fromsingletomarried.com</td>\n",
       "      <td>oh my – a little piece of heaven right there a...</td>\n",
       "      <td>['oh', '–', 'little', 'piece', 'heaven', 'righ...</td>\n",
       "      <td>['oh', '–', 'littl', 'piec', 'heaven', 'right'...</td>\n",
       "      <td>[(oh, my), (my, –), (–, a), (a, little), (litt...</td>\n",
       "      <td>[(oh, my, –), (my, –, a), (–, a, little), (a, ...</td>\n",
       "      <td>oh – little piece heaven right time holidays</td>\n",
       "      <td>oh – littl piec heaven right time holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>yes, please!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2009-11-17 11:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>sweet potato buttermilk pie</td>\n",
       "      <td>https://smittenkitchen.com/2009/11/sweet-potat...</td>\n",
       "      <td>yes, please!</td>\n",
       "      <td>Cari</td>\n",
       "      <td>none</td>\n",
       "      <td>yes, please!</td>\n",
       "      <td>['yes', 'please']</td>\n",
       "      <td>['ye', 'pleas']</td>\n",
       "      <td>[(yes,, please!)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>yes please</td>\n",
       "      <td>ye pleas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>ive never made sweet potato pie!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2009-11-17 11:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>sweet potato buttermilk pie</td>\n",
       "      <td>https://smittenkitchen.com/2009/11/sweet-potat...</td>\n",
       "      <td>Ive never made sweet potato pie! I’d love to t...</td>\n",
       "      <td>Jessica at How Sweet It Is</td>\n",
       "      <td>http://howsweeteats.com</td>\n",
       "      <td>ive never made sweet potato pie! i’d love to t...</td>\n",
       "      <td>['ive', 'never', 'made', 'sweet', 'potato', 'p...</td>\n",
       "      <td>['ive', 'never', 'made', 'sweet', 'potato', 'p...</td>\n",
       "      <td>[(ive, never), (never, made), (made, sweet), (...</td>\n",
       "      <td>[(ive, never, made), (never, made, sweet), (ma...</td>\n",
       "      <td>never made sweet potato pie</td>\n",
       "      <td>never made sweet potato pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>i’d love to try for the holidays!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2009-11-17 11:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>sweet potato buttermilk pie</td>\n",
       "      <td>https://smittenkitchen.com/2009/11/sweet-potat...</td>\n",
       "      <td>Ive never made sweet potato pie! I’d love to t...</td>\n",
       "      <td>Jessica at How Sweet It Is</td>\n",
       "      <td>http://howsweeteats.com</td>\n",
       "      <td>ive never made sweet potato pie! i’d love to t...</td>\n",
       "      <td>['ive', 'never', 'made', 'sweet', 'potato', 'p...</td>\n",
       "      <td>['ive', 'never', 'made', 'sweet', 'potato', 'p...</td>\n",
       "      <td>[(i’d, love), (love, to), (to, try), (try, for...</td>\n",
       "      <td>[(i’d, love, to), (love, to, try), (to, try, f...</td>\n",
       "      <td>i’d love try holidays</td>\n",
       "      <td>i’d love tri holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>this is definitely going on my must make list.</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2009-11-17 11:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>sweet potato buttermilk pie</td>\n",
       "      <td>https://smittenkitchen.com/2009/11/sweet-potat...</td>\n",
       "      <td>This is definitely going on my Must Make list....</td>\n",
       "      <td>LauraC</td>\n",
       "      <td>http://JonAndLaura.blogspot.com</td>\n",
       "      <td>this is definitely going on my must make list....</td>\n",
       "      <td>['definitely', 'going', 'must', 'make', 'list'...</td>\n",
       "      <td>['definit', 'go', 'must', 'make', 'list', 'nor...</td>\n",
       "      <td>[(this, is), (is, definitely), (definitely, go...</td>\n",
       "      <td>[(this, is, definitely), (is, definitely, goin...</td>\n",
       "      <td>definitely going must make list</td>\n",
       "      <td>definit go must make list</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                           sentence  commentID  \\\n",
       "0    other  oh my – a little piece of heaven right there a...          0   \n",
       "1    other                                       yes, please!          1   \n",
       "2    other                   ive never made sweet potato pie!          2   \n",
       "3    other                  i’d love to try for the holidays!          2   \n",
       "4    other     this is definitely going on my must make list.          3   \n",
       "\n",
       "   child_id children         comment_time  recipenumber  \\\n",
       "0         0       no  2009-11-17 11:44:00             0   \n",
       "1         0       no  2009-11-17 11:44:00             0   \n",
       "2         0       no  2009-11-17 11:44:00             0   \n",
       "3         0       no  2009-11-17 11:44:00             0   \n",
       "4         0       no  2009-11-17 11:44:00             0   \n",
       "\n",
       "                         title  \\\n",
       "0  sweet potato buttermilk pie   \n",
       "1  sweet potato buttermilk pie   \n",
       "2  sweet potato buttermilk pie   \n",
       "3  sweet potato buttermilk pie   \n",
       "4  sweet potato buttermilk pie   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://smittenkitchen.com/2009/11/sweet-potat...   \n",
       "1  https://smittenkitchen.com/2009/11/sweet-potat...   \n",
       "2  https://smittenkitchen.com/2009/11/sweet-potat...   \n",
       "3  https://smittenkitchen.com/2009/11/sweet-potat...   \n",
       "4  https://smittenkitchen.com/2009/11/sweet-potat...   \n",
       "\n",
       "                                         usercomment  \\\n",
       "0  Oh my – a little piece of heaven right there a...   \n",
       "1                                       yes, please!   \n",
       "2  Ive never made sweet potato pie! I’d love to t...   \n",
       "3  Ive never made sweet potato pie! I’d love to t...   \n",
       "4  This is definitely going on my Must Make list....   \n",
       "\n",
       "                           username                            usersite  \\\n",
       "0  Tabitha (From Single to Married)  http://www.fromsingletomarried.com   \n",
       "1                              Cari                                none   \n",
       "2        Jessica at How Sweet It Is             http://howsweeteats.com   \n",
       "3        Jessica at How Sweet It Is             http://howsweeteats.com   \n",
       "4                            LauraC     http://JonAndLaura.blogspot.com   \n",
       "\n",
       "                                   usercomment_lower  \\\n",
       "0  oh my – a little piece of heaven right there a...   \n",
       "1                                       yes, please!   \n",
       "2  ive never made sweet potato pie! i’d love to t...   \n",
       "3  ive never made sweet potato pie! i’d love to t...   \n",
       "4  this is definitely going on my must make list....   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['oh', '–', 'little', 'piece', 'heaven', 'righ...   \n",
       "1                                  ['yes', 'please']   \n",
       "2  ['ive', 'never', 'made', 'sweet', 'potato', 'p...   \n",
       "3  ['ive', 'never', 'made', 'sweet', 'potato', 'p...   \n",
       "4  ['definitely', 'going', 'must', 'make', 'list'...   \n",
       "\n",
       "                                      tokens_stemmed  \\\n",
       "0  ['oh', '–', 'littl', 'piec', 'heaven', 'right'...   \n",
       "1                                    ['ye', 'pleas']   \n",
       "2  ['ive', 'never', 'made', 'sweet', 'potato', 'p...   \n",
       "3  ['ive', 'never', 'made', 'sweet', 'potato', 'p...   \n",
       "4  ['definit', 'go', 'must', 'make', 'list', 'nor...   \n",
       "\n",
       "                                    sentence_bigrams  \\\n",
       "0  [(oh, my), (my, –), (–, a), (a, little), (litt...   \n",
       "1                                  [(yes,, please!)]   \n",
       "2  [(ive, never), (never, made), (made, sweet), (...   \n",
       "3  [(i’d, love), (love, to), (to, try), (try, for...   \n",
       "4  [(this, is), (is, definitely), (definitely, go...   \n",
       "\n",
       "                                   sentence_trigrams  \\\n",
       "0  [(oh, my, –), (my, –, a), (–, a, little), (a, ...   \n",
       "1                                                 []   \n",
       "2  [(ive, never, made), (never, made, sweet), (ma...   \n",
       "3  [(i’d, love, to), (love, to, try), (to, try, f...   \n",
       "4  [(this, is, definitely), (is, definitely, goin...   \n",
       "\n",
       "                                sentence_tokens  \\\n",
       "0  oh – little piece heaven right time holidays   \n",
       "1                                    yes please   \n",
       "2                   never made sweet potato pie   \n",
       "3                         i’d love try holidays   \n",
       "4               definitely going must make list   \n",
       "\n",
       "                     sentence_tokens_stemmed  \n",
       "0  oh – littl piec heaven right time holiday  \n",
       "1                                   ye pleas  \n",
       "2                never made sweet potato pie  \n",
       "3                       i’d love tri holiday  \n",
       "4                  definit go must make list  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_classified.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define test, train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_classified.to_csv('comments_classified_SK_filtered2000_additional.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "comments_classified.loc[:,'category_label'] = le.fit_transform(comments_classified.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments_classified.category.unique()\n",
    "# comments_classified.category.replace('try','other',inplace=True)\n",
    "# comments_classified.category.replace('addition','suggestion',inplace=True)\n",
    "# comments_classified.category.replace('subtraction','substitution',inplace=True)\n",
    "# comments_classified.category.replace('related','other',inplace=True)\n",
    "# comments_classified.category.replace('question','other',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = comments_classified[comments_classified.category != 'other'].sentence #\\.as_matrix()\n",
    "# target = comments_classified.category.as_matrix()\n",
    "target = comments_classified[comments_classified.category != 'other'].category_label #.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = comments_with_sentences.loc[2000:10000, 'sentence'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'other', 'substitution', 'suggestion']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['substitution', 'other', 'love'], dtype=object)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([2,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word relevancy - counter, tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 3967)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,3), stop_words=mystops)\n",
    "\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 3967)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "\n",
    "X_train_tf = transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "classifier = MultinomialNB().fit(X_train_tf, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = BernoulliNB().fit(X_train_counts, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_counts = vectorizer.transform(X_test)\n",
    "# X_test_tf = transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = classifier.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'except we’ll make them in a mini muffin pan so they’ll be brownie bites (otherwise they won’t survive until the weekend).' => 0\n",
      "'oh my goodness!' => 0\n",
      "'these were wonderful!' => 0\n",
      "'i have since discovering your website made the mushroom and brioche bites (the were like crack!' => 0\n",
      "'i couldn’t put them down!).' => 0\n",
      "'i made the caramel pudding.' => 0\n",
      "'yummy.' => 0\n",
      "'and now these brownies!' => 0\n",
      "'about 2 weeks ago all i wanted was brownies and went into whole food and bought what i thought were the most wonderful brownies ever!' => 0\n",
      "'until i made these!' => 0\n",
      "'my boyfriend and i have loved every last bite (though when i’m making them they made 9 per pan!!)' => 0\n",
      "'i think if i cut them into 25 squares i would actually end up eating more!' => 0\n",
      "'thanks for the awesome recipes!' => 0\n",
      "'this is quite similar to the alton brown recipe for cocoa brownies which i just happened to make today.' => 0\n",
      "'i don’t follow his mixing method though in favor for the king arthur one similar to alice’s recipe – melting the butter and sugar for a shiny top.' => 0\n",
      "'yum.' => 0\n",
      "'the ab recipe has a good bit more cocoa, two more eggs and six tablespoons more butter.' => 0\n",
      "'oh and about 1 more cup of sugar (split evenly between brown and white).' => 0\n",
      "'i made these brownies last night…they were delicous!' => 0\n",
      "'great recipe…thanks for posting!' => 0\n",
      "'i made these this past weekend and they were fabulous!' => 0\n",
      "'i halved the recipe and cooked them in a loaf pan lined with parchment and they turned out great.' => 0\n",
      "'i like that you have the weights on the recipe because i hate dirtying my measuring spoons/cups.' => 0\n",
      "'these look awesome.' => 0\n",
      "'have you ever tried recchiuti chocolate here is san francisco?' => 0\n",
      "'for me they took a bit longer than 25 minutes.' => 0\n",
      "'i left them to cool overnight, and they cut quite easily and neatly this morning.' => 0\n",
      "'this morning they seemed a bit “chewy.”  nontheless, i took them to work, but left them in the car (in the warm hawaiian sun).' => 0\n",
      "'when i finally brought them in they seemed improved.' => 0\n",
      "'they were dense, but fudgy and wonderful.' => 0\n",
      "'i used ghirardelli cocoa i buy in bulk at the health food store.' => 0\n",
      "'thanks for the recipe!' => 0\n",
      "'carolyn — sigh, “warm hawaiian sun”.' => 0\n",
      "'siiiiiigh.' => 0\n",
      "'i saw this post tonight, and i had to make them tonight!' => 0\n",
      "'i love that this is a good “i need brownies on a wednesday night, i wonder what’s in the cupboards” recipe, and they’re moist and chewy and very chocolatey!' => 0\n",
      "'i had the perfect amount of cocoa left in the can, so i figured it was destiny.' => 0\n",
      "'i used dagoba cocoa.' => 0\n",
      "'i used the microwave to heat the butter/ cocoa mixture and it worked out just fine.' => 0\n",
      "'i checked every 30-40 seconds and stirred.' => 0\n",
      "'i used mini-muffin pans, greased, to which i delivered heaping scoops of batter using a 1 1/4″ ice cream scoop (i got at the shop in chelsea you’ve previously talked about when i went to visit friends in nyc- i am a dork and wanted a food-related souvenir even though i could easily get this item in the bay area :p ).' => 0\n",
      "'i baked 10 minutes, rotated the pans, and then another 8-10 minutes.' => 0\n",
      "'i made these yesterday and they are really wonderfull.' => 0\n",
      "'and, also important, very easy to make without going to a shop.' => 0\n",
      "'butter, flower, cocoa powder and eggs are things we always have in our cupboard.' => 0\n",
      "'so perfectly to make this for unexpected visitors.' => 0\n",
      "'i made these today.' => 0\n",
      "'loved the dense chewiness and they definitely hit the chocolate spot but that’s still way too much chocolate for my taste buds.' => 0\n",
      "'i’d probably cut the cocoa by a third or even a half next time.' => 0\n",
      "'(i used nestlé toll house cocoa.)' => 0\n",
      "'where was this last night when i was scanning my blogs for a new brownie recipe!' => 0\n",
      "'those look divine and exactly what i was looking for in a brownie!' => 0\n",
      "'you know, not til you said everything about tempered bars vs cocoa powder in brownies did i think i was the minority!' => 0\n",
      "'i always always have used nothing but cocoa powder.' => 0\n",
      "'just how i was raised.' => 0\n",
      "'if a recipe calls for melted chocolate, i do the cocoa powder and butter/shortening/ oil route instead.' => 0\n",
      "'something about cocoa powder always seems to equal brownies to me.' => 0\n",
      "'not melted chocolate.' => 0\n",
      "'this is a definite recipe to try though.' => 0\n",
      "'thanks!' => 0\n",
      "'ok these are to die for!' => 0\n",
      "'i made one batch to give away and was immeditaly requested to make another once the leftover brownies were tasted.' => 0\n",
      "'my new go to.' => 0\n",
      "'thanks deb!' => 0\n",
      "'!' => 0\n",
      "'these were amazing!' => 0\n",
      "'i even took the shortcut of melting the butter and cocoa mixture using the microwave and they turned out incredibly well.' => 0\n",
      "'they’re moist and chewy and just the right amount of chocolate (although i also added some chips to the top of 1/2 of the pan and that was a nice addition as well, granted i have an insatiable sweet tooth).' => 0\n",
      "'i just made these.' => 0\n",
      "'and ate a tenth of the pan before they finished cooling.' => 0\n",
      "'man, these are good.' => 0\n",
      "'i hope they get slightly grosser as they cool, otherwise there won’t be any left for me to bring to our friends’ tonight.' => 0\n",
      "'we just made these – unreal!' => 0\n",
      "'so so good!' => 0\n",
      "'we split them amongst 3 friends, i got 5 pieces…and well there’s only 2 left.' => 0\n",
      "'with the snow storm coming tomorrow, doubtful there will be any left by noon tomorrow.' => 0\n",
      "'=)' => 0\n",
      "'i am so excited to make these!' => 0\n",
      "'i bake almost everything from scratch, but i’ve always secretly preferred box-mix brownies to homemade.' => 0\n",
      "'i’m so glad that i’m not alone, and that there is hope to make yummy brownies from scratch!' => 0\n",
      "'loved this recipe!' => 0\n",
      "'the brownies were fudgy and delicious!' => 0\n",
      "'i substituted the walnuts for chocolate chips and then topped with powdered sugar : ) and i did the microwave route to melt the chocolate and it worked perfect.' => 0\n",
      "'i was wrong, these won’t make it until tomorrow *leers at the three brownies she brought to work* i need to make a double batch next time.' => 0\n",
      "'in the uk- oxfam’s ‘divine’ cocoa powder is the best on the market- it’s like a whole higher realm of chocolate..(and it’s free trade).. where other brands are dry dust, this one is as rich as snuff, moist, oily and dark….arggggggggglegh….' => 0\n",
      "'just made these — awesome!!' => 0\n",
      "'disappeared in record time when shared at work.' => 0\n",
      "'i used hershey’s special dark like many others, and they were perfectly chocolatey with a unique (to me), almost black color.' => 2\n",
      "'also added some leftover andes baking pieces — i really like the sweet, bright mint and the dark, fudgy chocolate.' => 0\n",
      "'i don’t like nuts in baked goods but always like a little texture/flavor complexity….' => 0\n",
      "'hence the addition!' => 0\n",
      "'amazing!' => 0\n",
      "'i used droste dutched cocoa, they baked in 25 minutes, and were dark, deep chocolate-y.' => 0\n",
      "'my 4 year old wasn’t a fan, but my husband loved every bite.' => 0\n",
      "'iusually make the ci brownies.' => 0\n",
      "'i think these are more “adult”, not as sweet.' => 0\n",
      "'i think my next dinner party will feature a brownie throwdown!' => 0\n",
      "'i have a pan in the oven now, using hershey’s special dark cocoa, (looked like coffee grounds after the first step!' => 2\n",
      "'), and some crushed heath bars that i had in the freezer.' => 0\n",
      "'we’ll be taking them camping tomorrow…if i can wait that long to sample them.' => 0\n"
     ]
    }
   ],
   "source": [
    "for doc, category in zip(X_test[:100], predicted[:100]):\n",
    "    print('%r => %s' % (doc, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other', 'other', 'other', ..., 'other', 'other', 'other'], \n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments_classified.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-a51f31abca38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_count' is not defined"
     ]
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components=10)\n",
    "\n",
    "pca.fit(X_train_count)\n",
    "X_trans = pca.transform(X_train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_target(df, target_column):\n",
    "    \"\"\"Add column to df with integers for the target.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    df -- pandas DataFrame.\n",
    "    target_column -- column to map to int, producing\n",
    "                     new Target column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_mod -- modified DataFrame.\n",
    "    targets -- list of target names.\n",
    "    \"\"\"\n",
    "    df_mod = df.copy()\n",
    "    targets = df_mod[target_column].unique()\n",
    "    map_to_int = {name: n for n, name in enumerate(targets)}\n",
    "    df_mod[\"Target\"] = df_mod[target_column].replace(map_to_int)\n",
    "\n",
    "    return (df_mod, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = encode_target(comments_classified, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments_classified.loc[comments_classified.sentence.str.contains('instead of') == True, 'category'] = 'substitution'\n",
    "\n",
    "# comments_classified"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "comments_classified[comments_classified.sentence.str.contains('perfect for') == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_classifier = DecisionTreeClassifier(max_depth=3, max_features=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_fit = tree_classifier.fit(X_train_counts, target)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1999, 19)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_classified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['child_id', 'children', 'commentID', 'comment_time', 'recipenumber',\n",
       "       'title', 'url', 'usercomment', 'username', 'usersite'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
